{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOiL8QFKzPH+Tpt42wWggmC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CODEMAN251/mnist-cnn-onnx/blob/main/Code0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYMNM2kZjdR0"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision opencv-python matplotlib numpy pandas onnx onnxruntime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()  # Upload kaggle.json here"
      ],
      "metadata": {
        "id": "g_tapJG4ksj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "z_c48s8enFkT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d meowmeowmeowmeowmeow/gtsrb-german-traffic-sign\n",
        "!unzip gtsrb-german-traffic-sign.zip -d gtsrb_data"
      ],
      "metadata": {
        "id": "5KRaNHyInZgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch\n",
        "\n",
        "class GTSRBDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.images = []\n",
        "        self.labels = []\n",
        "        self.transform = transform\n",
        "        self.classes = sorted(os.listdir(root_dir))\n",
        "\n",
        "        for label, class_folder in enumerate(self.classes):\n",
        "            class_path = os.path.join(root_dir, class_folder)\n",
        "            for img_name in os.listdir(class_path):\n",
        "                if img_name.endswith(\".ppm\") or img_name.endswith(\".png\") or img_name.endswith(\".jpg\"):\n",
        "                    self.images.append(os.path.join(class_path, img_name))\n",
        "                    self.labels.append(label)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.images[idx])\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        return img, label"
      ],
      "metadata": {
        "id": "W5-qw4htoJr7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define image transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))  # For grayscale; update if color\n",
        "])\n",
        "\n",
        "# Create datasets\n",
        "dataset = GTSRBDataset(root_dir=\"gtsrb_data/Train\", transform=transform)\n",
        "\n",
        "# Split into training and validation\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "print(f\"‚úÖ Datasets ready ‚Äî {len(train_dataset)} train, {len(val_dataset)} val\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7-GD-Aboar9",
        "outputId": "5cd12420-35a9-4afd-dfb8-0b86bacdcda9"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Datasets ready ‚Äî 31367 train, 7842 val\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define transform\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Converts [0, 255] ‚Üí [0.0, 1.0]\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize to [-1, 1]\n",
        "])\n",
        "\n",
        "# Load datasets\n",
        "train_dataset = torchvision.datasets.MNIST(root=\"./data\", train=True, transform=transform, download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root=\"./data\", train=False, transform=transform, download=True)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "print(f\"‚úÖ MNIST Loaded: {len(train_dataset)} train, {len(test_dataset)} test\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRraeVXNoyat",
        "outputId": "35afd6fb-b407-49dd-84fe-7b530c8e41b0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9.91M/9.91M [00:01<00:00, 5.08MB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28.9k/28.9k [00:00<00:00, 135kB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.65M/1.65M [00:01<00:00, 1.27MB/s]\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.54k/4.54k [00:00<00:00, 7.02MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ MNIST Loaded: 60000 train, 10000 test\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize a few samples\n",
        "examples = enumerate(train_loader)\n",
        "batch_idx, (example_data, example_targets) = next(examples)\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "for i in range(6):\n",
        "    plt.subplot(1,6,i+1)\n",
        "    plt.imshow(example_data[i][0], cmap='gray')\n",
        "    plt.title(f\"Label: {example_targets[i]}\")\n",
        "    plt.axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "collapsed": true,
        "id": "XwBIw_4lo4z1",
        "outputId": "7b937c37-2a43-40ec-ef7d-ed551541882d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)  # output: 32x28x28\n",
        "        self.pool = nn.MaxPool2d(2, 2)  # output after pool: 32x14x14\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)  # output: 64x14x14\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)  # 10 classes\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))   # -> [32, 14, 14]\n",
        "        x = self.pool(torch.relu(self.conv2(x)))   # -> [64, 7, 7]\n",
        "        x = x.view(-1, 64 * 7 * 7)  # Flatten\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "WK8hjON9qiUs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = SimpleCNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "DsuR2YKrqo-9"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"üìà Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TrJrEz1qvc_",
        "outputId": "30eee590-d239-4f7e-f025-dbfe5a7dc3b3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìà Epoch 1/5, Loss: 0.1515\n",
            "üìà Epoch 2/5, Loss: 0.0439\n",
            "üìà Epoch 3/5, Loss: 0.0306\n",
            "üìà Epoch 4/5, Loss: 0.0226\n",
            "üìà Epoch 5/5, Loss: 0.0180\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f\"üéØ Test Accuracy: {100 * correct / total:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKo7nHFirMYF",
        "outputId": "f6ca56ac-564f-4dbf-f928-aac8d410ed67"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéØ Test Accuracy: 99.18%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"mnist_cnn.pth\")\n",
        "print(\"‚úÖ PyTorch model saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpCpF6Yrrga-",
        "outputId": "fc2f6b62-a2bb-482a-9350-a818185c0979"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ PyTorch model saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_input = torch.randn(1, 1, 28, 28, device=device)  # (batch_size, channels, height, width)\n",
        "\n",
        "torch.onnx.export(\n",
        "    model,\n",
        "    dummy_input,\n",
        "    \"mnist_cnn.onnx\",\n",
        "    input_names=['input'],\n",
        "    output_names=['output'],\n",
        "    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}},\n",
        "    opset_version=11\n",
        ")\n",
        "\n",
        "print(\"üì¶ Model exported to ONNX: mnist_cnn.onnx\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4oYPsLfriy1",
        "outputId": "5822705d-befa-4885-ae95-c04cf9dcf51b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì¶ Model exported to ONNX: mnist_cnn.onnx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import onnx\n",
        "\n",
        "model_onnx = onnx.load(\"mnist_cnn.onnx\")\n",
        "onnx.checker.check_model(model_onnx)\n",
        "print(\"‚úÖ ONNX model is valid!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DHBo3exvrxj-",
        "outputId": "63cc238a-32c4-485b-a95d-e4c789bb89e9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ ONNX model is valid!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime"
      ],
      "metadata": {
        "id": "7L-Ilw4yr_bS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime as ort\n",
        "import numpy as np\n",
        "\n",
        "# Load ONNX model\n",
        "ort_session = ort.InferenceSession(\"mnist_cnn.onnx\")\n",
        "\n",
        "# Get one sample image from test set\n",
        "image, label = test_dataset[0]\n",
        "image = image.unsqueeze(0).numpy()  # shape: [1, 1, 28, 28]\n",
        "\n",
        "# Run inference\n",
        "outputs = ort_session.run(None, {\"input\": image})\n",
        "predicted_class = np.argmax(outputs[0])\n",
        "\n",
        "print(f\"üñºÔ∏è True Label: {label}, üéØ Predicted: {predicted_class}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4Mvui2asDFY",
        "outputId": "54ae7b73-eb0b-41ea-a5d1-b2af6133185d"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üñºÔ∏è True Label: 7, üéØ Predicted: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(image.squeeze(), cmap='gray')\n",
        "plt.title(f\"Predicted: {predicted_class}\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "SRx-5nyrsRx_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}